{
  "source": {
    "host": "as400.company.com",
    "library": "PRODLIB",
    "table": "CUSTOMERS",
    "username": "etl_user",
    "password": "secure_password",
    "columns": [
      {"name": "CUST_ID", "type": "string"},
      {"name": "NAME", "type": "string", "clean_strings": true},
      {"name": "ADDRESS", "type": "string", "clean_strings": true},
      {"name": "LAST_UPDATE", "type": "timestamp"}
    ],
    "checkpoint_column": "LAST_UPDATE",
    "partition_column": "CUST_ID",
    "num_partitions": 20,
    "clean_delimiters": true,
    "string_handling": {
      "replace_cr": true,
      "replace_lf": true,
      "replace_tab": true
    },
    "jdbc_properties": {
      "prompt": "false",
      "lob threshold": "1048576",
      "translate binary": "true"
    }
  },
  "targets": {
    "hive": {
      "table": "dw.customer_dim",
      "append": true,
      "pre_write_sql": "SELECT cust_id, trim(name) as customer_name, address, last_update FROM temp_customers WHERE status = 'ACTIVE'"
    },
    "teradata": {
      "host": "tdprod.company.com",
      "database": "EDW_PROD",
      "table": "CUSTOMER_DIM",
      "username": "td_loader",
      "password": "loader_pwd",
      "append": true,
      "batch_size": 10000,
      "transaction": true,
      "pre_write_sql": "SELECT cust_id, upper(name) as customer_name, address, last_update, current_timestamp as load_ts FROM temp_customers"
    },
    "file": {
      "path": "/data/export/customers",
      "format": "parquet",
      "clean_delimiters": true,
      "delimiter_handling": {
        "escape": "\\",
        "multiLine": true
      }
    }
  },
  "transformations": [
    {
      "type": "literal",
      "column": "LOAD_TIMESTAMP",
      "value": "CURRENT_TIMESTAMP"
    }
  ],
  "logging": {
    "kudu_master": "kudu-master.company.com:7051",
    "kudu_table": "impala::default.etl_job_logs",
    "checkpoint_table": "impala::default.etl_checkpoints"
  },
  "spark_config": {
    "spark.executor.memory": "8g",
    "spark.driver.memory": "4g",
    "spark.executor.cores": "4",
    "spark.executor.instances": "10",
    "spark.dynamicAllocation.enabled": "true",
    "spark.sql.shuffle.partitions": "200",
    "spark.jars": "/path/to/jt400.jar,/path/to/terajdbc4.jar"
  }
}
